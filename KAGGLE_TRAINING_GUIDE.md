# Kaggle äº‘ç«¯è®­ç»ƒæŒ‡å—

## ğŸŒ ä¸ºä»€ä¹ˆä½¿ç”¨ Kaggle

Kaggle æä¾›å…è´¹çš„ GPU èµ„æºç”¨äºè®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼š
- âœ… **å…è´¹ GPU**: Tesla P100 æˆ– T4 (16GB æ˜¾å­˜)
- âœ… **æ¯å‘¨ 30 å°æ—¶**: GPU ä½¿ç”¨æ—¶é•¿
- âœ… **æŒä¹…åŒ–å­˜å‚¨**: å¯ä»¥ä¿å­˜æ¨¡å‹
- âœ… **Jupyter ç¯å¢ƒ**: æ–¹ä¾¿è°ƒè¯•
- âœ… **æ— éœ€æœ¬åœ°èµ„æº**: äº‘ç«¯è¿è¡Œ

---

## ğŸ“‹ å‡†å¤‡æ­¥éª¤

### 1. æ³¨å†Œ Kaggle è´¦å·
1. è®¿é—® [kaggle.com](https://www.kaggle.com)
2. æ³¨å†Œè´¦å·å¹¶éªŒè¯æ‰‹æœºå·ï¼ˆè·å– GPU æƒé™ï¼‰

### 2. å¯ç”¨ GPU
1. è¿›å…¥ä»»æ„ Notebook
2. åœ¨å³ä¾§ Settings â†’ Accelerator â†’ é€‰æ‹© **GPU T4 x2** æˆ– **GPU P100**

---

## ğŸš€ æ–¹æ¡ˆä¸€ï¼šKaggle Notebook (æ¨èæ–°æ‰‹)

### Step 1: åˆ›å»ºæ–° Notebook
1. ç™»å½• Kaggle
2. ç‚¹å‡» "Code" â†’ "New Notebook"
3. å³ä¾§è®¾ç½®:
   - Accelerator: **GPU T4 x2**
   - Internet: **On**
   - Persistence: **Files only**

### Step 2: ä¸Šä¼ é¡¹ç›®æ–‡ä»¶

åœ¨ Notebook ç¬¬ä¸€ä¸ª Cell ä¸­ï¼š

```python
# åˆ›å»ºé¡¹ç›®ç›®å½•
!mkdir -p /kaggle/working/xq

# ä¸Šä¼ æ–¹å¼1: ä½¿ç”¨ Kaggle Dataset
# å…ˆåœ¨æœ¬åœ°æŠŠé¡¹ç›®æ‰“åŒ…æˆ zipï¼Œä¸Šä¼ ä¸º Kaggle Dataset
# ç„¶ååœ¨ Notebook ä¸­æ·»åŠ è¿™ä¸ª Dataset

# ä¸Šä¼ æ–¹å¼2: ç›´æ¥ä» GitHub (å¦‚æœä½ æœ‰ä»“åº“)
# !git clone https://github.com/your-username/xq.git /kaggle/working/xq

# ä¸Šä¼ æ–¹å¼3: ä½¿ç”¨ Kaggle çš„æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½
# ç‚¹å‡»å³ä¾§ Data â†’ Upload Dataset
```

### Step 3: å®‰è£…ä¾èµ–

```python
%%bash
cd /kaggle/working/xq
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118
```

### Step 4: å¼€å§‹è®­ç»ƒ

```python
%%bash
cd /kaggle/working/xq

python train_rl_ai_optimized.py \
    --games 100 \
    --iterations 500 \
    --train-steps 500 \
    --batch-size 512 \
    --parallel-games 8 \
    --num-channels 256 \
    --num-res-blocks 20 \
    --save-interval 20 \
    --save-dir /kaggle/working/models
```

### Step 5: ä¿å­˜æ¨¡å‹

```python
# è®­ç»ƒå®Œæˆåï¼Œä¸‹è½½æ¨¡å‹
from IPython.display import FileLink
import os

# åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
for f in os.listdir('/kaggle/working/models'):
    if f.endswith('.pth'):
        display(FileLink(f'/kaggle/working/models/{f}'))
```

---

## ğŸ¯ æ–¹æ¡ˆäºŒï¼šæ‰“åŒ…ä¸Šä¼  (æ¨èè¿›é˜¶)

### Step 1: æœ¬åœ°å‡†å¤‡

åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º `kaggle_setup.py`:

```python
#!/usr/bin/env python3
"""
Kaggle ç¯å¢ƒè®¾ç½®è„šæœ¬
è‡ªåŠ¨æ£€æµ‹å¹¶é…ç½® Kaggle ç¯å¢ƒ
"""
import os
import sys
import subprocess

def is_kaggle():
    """æ£€æµ‹æ˜¯å¦åœ¨ Kaggle ç¯å¢ƒä¸­"""
    return os.path.exists('/kaggle')

def setup_kaggle_env():
    """é…ç½® Kaggle ç¯å¢ƒ"""
    print("æ£€æµ‹åˆ° Kaggle ç¯å¢ƒï¼Œå¼€å§‹é…ç½®...")
    
    # æ˜¾ç¤º GPU ä¿¡æ¯
    print("\nGPU ä¿¡æ¯:")
    subprocess.run(['nvidia-smi'])
    
    # å®‰è£…ä¾èµ–ï¼ˆKaggle å·²é¢„è£… PyTorchï¼Œä½†å¯èƒ½éœ€è¦æ›´æ–°ï¼‰
    print("\næ£€æŸ¥ä¾èµ–...")
    
    # è®¾ç½®å·¥ä½œç›®å½•
    work_dir = '/kaggle/working/xq'
    if not os.path.exists(work_dir):
        os.makedirs(work_dir)
    
    print(f"\nå·¥ä½œç›®å½•: {work_dir}")
    print(f"è¾“å‡ºç›®å½•: /kaggle/working/models")
    
    return work_dir

def main():
    if is_kaggle():
        work_dir = setup_kaggle_env()
        print("\nâœ“ Kaggle ç¯å¢ƒé…ç½®å®Œæˆï¼")
        print(f"\nå¼€å§‹è®­ç»ƒå‘½ä»¤:")
        print(f"cd {work_dir}")
        print(f"python train_rl_ai_optimized.py --save-dir /kaggle/working/models")
    else:
        print("æœªæ£€æµ‹åˆ° Kaggle ç¯å¢ƒï¼Œä½¿ç”¨æœ¬åœ°é…ç½®")

if __name__ == "__main__":
    main()
```

### Step 2: åˆ›å»ºæ‰“åŒ…è„šæœ¬

åˆ›å»º `prepare_kaggle.py`:

```python
#!/usr/bin/env python3
"""
å‡†å¤‡ Kaggle ä¸Šä¼ åŒ…
"""
import os
import zipfile
import shutil

def create_kaggle_package():
    """åˆ›å»º Kaggle ä¸Šä¼ åŒ…"""
    
    # éœ€è¦åŒ…å«çš„æ–‡ä»¶
    include_files = [
        # æ ¸å¿ƒä»£ç 
        'train_rl_ai_optimized.py',
        'kaggle_setup.py',
        
        # æ¨¡å—
        'ai/__init__.py',
        'ai/ai_player.py',
        'ai/mcts_ai.py',
        
        'core/__init__.py',
        'core/game_state.py',
        'core/interfaces.py',
        
        'game/__init__.py',
        'game/dark_chess_board.py',
        'game/dark_chess_piece.py',
        'game/game_engine.py',
        'game/zobrist_hash.py',
        
        'players/__init__.py',
        'players/ai_player.py',
        'players/base_player.py',
        'players/human_player.py',
        
        'rl_ai/__init__.py',
        'rl_ai/neural_network.py',
        'rl_ai/rl_player.py',
        'rl_ai/rl_trainer.py',
        
        # æ–‡æ¡£
        'README.md',
        'QUICK_START_OPTIMIZED.md',
    ]
    
    output_zip = 'xq_kaggle.zip'
    
    print(f"åˆ›å»º Kaggle ä¸Šä¼ åŒ…: {output_zip}")
    
    with zipfile.ZipFile(output_zip, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for file in include_files:
            if os.path.exists(file):
                zipf.write(file)
                print(f"  âœ“ {file}")
            else:
                print(f"  âœ— {file} (ä¸å­˜åœ¨)")
    
    print(f"\nå®Œæˆ! ä¸Šä¼ åŒ…å¤§å°: {os.path.getsize(output_zip) / 1024:.1f} KB")
    print(f"\nä¸‹ä¸€æ­¥:")
    print(f"1. è®¿é—® kaggle.com/datasets")
    print(f"2. ç‚¹å‡» 'New Dataset'")
    print(f"3. ä¸Šä¼  {output_zip}")
    print(f"4. åœ¨ Notebook ä¸­æ·»åŠ è¿™ä¸ª Dataset")

if __name__ == "__main__":
    create_kaggle_package()
```

### Step 3: æ‰§è¡Œæ‰“åŒ…

```bash
# æœ¬åœ°è¿è¡Œ
python prepare_kaggle.py
```

### Step 4: ä¸Šä¼ åˆ° Kaggle

1. è®¿é—® [kaggle.com/datasets](https://www.kaggle.com/datasets)
2. ç‚¹å‡» **New Dataset**
3. ä¸Šä¼  `xq_kaggle.zip`
4. å¡«å†™ä¿¡æ¯:
   - Title: `Chinese Dark Chess RL Training`
   - Subtitle: `æ­æ£‹ AI è®­ç»ƒä»£ç `
5. ç‚¹å‡» **Create**

### Step 5: åœ¨ Notebook ä¸­ä½¿ç”¨

```python
# æ–°å»º Notebookï¼Œæ·»åŠ åˆšä¸Šä¼ çš„ Dataset

# Cell 1: è§£å‹
!unzip -q /kaggle/input/chinese-dark-chess-rl-training/xq_kaggle.zip -d /kaggle/working/xq
!ls /kaggle/working/xq

# Cell 2: é…ç½®ç¯å¢ƒ
!cd /kaggle/working/xq && python kaggle_setup.py

# Cell 3: å¼€å§‹è®­ç»ƒ
!cd /kaggle/working/xq && python train_rl_ai_optimized.py \
    --games 100 \
    --iterations 500 \
    --batch-size 512 \
    --parallel-games 8 \
    --num-channels 256 \
    --num-res-blocks 20 \
    --save-dir /kaggle/working/models \
    --save-interval 20

# Cell 4: ç›‘æ§ (è¿è¡Œæ—¶)
!nvidia-smi
!ls -lh /kaggle/working/models/

# Cell 5: æ‰“åŒ…ä¸‹è½½
!cd /kaggle/working && tar -czf models_kaggle.tar.gz models/
```

---

## ğŸ“ æ–¹æ¡ˆä¸‰ï¼šä½¿ç”¨ Kaggle Datasets æŒä¹…åŒ–

### åˆ›å»ºç‰ˆæœ¬ç®¡ç†

```python
# è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ ç‰ˆæœ¬ä¿å­˜
import kaggle
from datetime import datetime

def save_to_kaggle_dataset(model_dir):
    """ä¿å­˜æ¨¡å‹åˆ° Kaggle Dataset"""
    version_name = f"v{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # ä½¿ç”¨ Kaggle API
    # éœ€è¦å…ˆé…ç½® kaggle.json
    os.system(f"""
        kaggle datasets version -p {model_dir} \
        -m "Training checkpoint {version_name}"
    """)

# åœ¨è®­ç»ƒå¾ªç¯ä¸­è°ƒç”¨
if (iteration + 1) % 50 == 0:
    save_to_kaggle_dataset('/kaggle/working/models')
```

---

## ğŸ“Š æ€§èƒ½å¯¹æ¯”

| ç¯å¢ƒ | GPU | æ˜¾å­˜ | é€Ÿåº¦ | è´¹ç”¨ |
|------|-----|------|------|------|
| **æœ¬åœ° RTX 3060** | RTX 3060 | 12GB | 100% | ç”µè´¹ |
| **Kaggle T4** | Tesla T4 | 16GB | 80-90% | å…è´¹ (30h/å‘¨) |
| **Kaggle P100** | Tesla P100 | 16GB | 120-130% | å…è´¹ (30h/å‘¨) |
| **Google Colab** | T4/V100 | 15-16GB | 80-100% | å…è´¹ (é™æ—¶) |

ğŸ’¡ **å»ºè®®**: Kaggle P100 æ¯” RTX 3060 è¿˜å¿« 20-30%ï¼

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. ä¼šè¯é™åˆ¶
- Kaggle Notebook è¿è¡Œæ—¶é—´: **12å°æ—¶**
- è¶…æ—¶åè‡ªåŠ¨åœæ­¢
- éœ€è¦å®šæœŸä¿å­˜æ¨¡å‹

### 2. æŒä¹…åŒ–ç­–ç•¥

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ è‡ªåŠ¨ä¿å­˜
import time
import signal

def setup_auto_save(trainer, save_dir):
    """è®¾ç½®è‡ªåŠ¨ä¿å­˜"""
    def save_checkpoint(signum, frame):
        print("\næ£€æµ‹åˆ°ä¸­æ–­ï¼Œä¿å­˜æ£€æŸ¥ç‚¹...")
        trainer.save_checkpoint(f'{save_dir}/checkpoint_interrupt.pth')
        sys.exit(0)
    
    signal.signal(signal.SIGTERM, save_checkpoint)
    signal.signal(signal.SIGINT, save_checkpoint)

# ä½¿ç”¨
setup_auto_save(trainer, '/kaggle/working/models')
```

### 3. æ–­ç‚¹ç»­è®­

```python
# æ£€æŸ¥æ˜¯å¦æœ‰ä¹‹å‰çš„æ¨¡å‹
checkpoint_path = '/kaggle/working/models/checkpoint_interrupt.pth'
if os.path.exists(checkpoint_path):
    print(f"å‘ç°æ£€æŸ¥ç‚¹ï¼Œç»§ç»­è®­ç»ƒ: {checkpoint_path}")
    trainer.load_checkpoint(checkpoint_path)
```

---

## ğŸ”„ å¤šæ¬¡è®­ç»ƒç­–ç•¥

### ç­–ç•¥ 1: åˆ†æ®µè®­ç»ƒ
```bash
# ç¬¬ä¸€æ¬¡: è®­ç»ƒ 100 è½®
python train_rl_ai_optimized.py --iterations 100 --save-dir /kaggle/working/models

# ä¸‹è½½ model_final.pth åˆ°æœ¬åœ°

# ç¬¬äºŒæ¬¡: ä¸Šä¼ æ¨¡å‹ï¼Œç»§ç»­è®­ç»ƒ
python train_rl_ai_optimized.py \
    --load-model /kaggle/input/previous-model/model_final.pth \
    --iterations 100 \
    --save-dir /kaggle/working/models
```

### ç­–ç•¥ 2: è‡ªåŠ¨å¾ªç¯
```python
# åœ¨ Notebook ä¸­
total_iterations = 500
batch_size = 100  # æ¯æ¬¡è®­ç»ƒ 100 è½®

for i in range(0, total_iterations, batch_size):
    print(f"\n{'='*60}")
    print(f"è®­ç»ƒæ‰¹æ¬¡: {i//batch_size + 1}/{total_iterations//batch_size}")
    print(f"{'='*60}\n")
    
    # æ£€æŸ¥ä¹‹å‰çš„æ¨¡å‹
    if i > 0:
        load_model = f'/kaggle/working/models/model_iter_{i}.pth'
    else:
        load_model = None
    
    # è¿è¡Œè®­ç»ƒ
    !python train_rl_ai_optimized.py \
        --load-model {load_model} \
        --iterations {batch_size} \
        --save-dir /kaggle/working/models
    
    # ä¿å­˜åˆ° Datasetï¼ˆå¯é€‰ï¼‰
    # ... ä¸Šä¼ ä»£ç  ...
```

---

## ğŸ“± å…¶ä»–äº‘å¹³å°é€‰æ‹©

### Google Colab
- **ä¼˜ç‚¹**: å¯èƒ½æœ‰ V100/A100
- **ç¼ºç‚¹**: éšæœºæ–­çº¿ï¼Œä¸ç¨³å®š
- **é€‚åˆ**: çŸ­æœŸæµ‹è¯•

### Paperspace Gradient
- **ä¼˜ç‚¹**: ç¨³å®šï¼ŒæŒä¹…åŒ–å¥½
- **ç¼ºç‚¹**: å…è´¹é¢åº¦å°‘
- **é€‚åˆ**: é•¿æœŸè®­ç»ƒ

### AWS/Azure/GCP
- **ä¼˜ç‚¹**: ä¸“ä¸šï¼Œç¨³å®š
- **ç¼ºç‚¹**: æ”¶è´¹
- **é€‚åˆ**: ç”Ÿäº§ç¯å¢ƒ

---

## ğŸ¯ æ¨èå·¥ä½œæµ

### é˜¶æ®µ 1: æœ¬åœ°æµ‹è¯• (1-2å¤©)
```bash
# å°è§„æ¨¡æµ‹è¯•é…ç½®
python train_rl_ai_optimized.py --games 20 --iterations 50
```

### é˜¶æ®µ 2: Kaggle è®­ç»ƒ (1å‘¨)
- ä¸Šä¼ ä»£ç åˆ° Kaggle Dataset
- åˆ›å»º Notebookï¼Œæ¯æ¬¡è®­ç»ƒ 100 è½®
- æ¯å¤©æ£€æŸ¥ 1-2 æ¬¡ï¼Œä¸‹è½½æ¨¡å‹

### é˜¶æ®µ 3: æœ¬åœ°éªŒè¯
```bash
# ä¸‹è½½ Kaggle è®­ç»ƒçš„æ¨¡å‹
python main.py
# æµ‹è¯• AI å¼ºåº¦
```

### é˜¶æ®µ 4: ç»§ç»­ä¼˜åŒ–
- æ ¹æ®æµ‹è¯•ç»“æœè°ƒæ•´å‚æ•°
- ä¸Šä¼ æ–°é…ç½®åˆ° Kaggle
- ç»§ç»­è®­ç»ƒ

---

## ğŸ’¡ çœæ—¶æŠ€å·§

1. **ä½¿ç”¨å¿«ç…§**: æ¯ 20 è½®ä¿å­˜ä¸€æ¬¡
2. **å¤šè´¦å·**: æ³¨å†Œå¤šä¸ª Kaggle è´¦å·ï¼ˆéµå®ˆ ToSï¼‰
3. **æ··åˆè®­ç»ƒ**: Kaggle + æœ¬åœ°åŒæ—¶è¿›è¡Œ
4. **å‚æ•°è°ƒä¼˜**: åœ¨æœ¬åœ°å°è§„æ¨¡æµ‹è¯•æœ€ä½³å‚æ•°

---

## ğŸ“š ç›¸å…³èµ„æº

- [Kaggle Notebooks æ–‡æ¡£](https://www.kaggle.com/docs/notebooks)
- [Kaggle API æ–‡æ¡£](https://github.com/Kaggle/kaggle-api)
- [Google Colab](https://colab.research.google.com)

---

## ğŸš€ å¿«é€Ÿå¼€å§‹å‘½ä»¤

```bash
# 1. å‡†å¤‡ä¸Šä¼ åŒ…
python prepare_kaggle.py

# 2. ä¸Šä¼ åˆ° Kaggle Dataset

# 3. åœ¨ Kaggle Notebook ä¸­è¿è¡Œ
!unzip /kaggle/input/your-dataset/xq_kaggle.zip -d /kaggle/working/xq
!cd /kaggle/working/xq && python train_rl_ai_optimized.py \
    --games 100 --iterations 100 --batch-size 512 --parallel-games 8 \
    --save-dir /kaggle/working/models
```

å¼€å§‹åœ¨äº‘ç«¯å…è´¹è®­ç»ƒå§ï¼ğŸ‰
