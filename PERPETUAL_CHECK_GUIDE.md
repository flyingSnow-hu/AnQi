# 长将检测实现说明

## 功能概述

已为揭棋游戏实现完整的"长将"检测和判罚机制。

## 核心组件

### 1. 游戏状态追踪 (`core/game_state.py`)

新增属性:
- `consecutive_checks`: 连续将军次数
- `checking_side`: 当前将军方('red'或'black')
- `is_loss_by_perpetual_check`: 是否因长将判负
- `perpetual_check_threshold`: 长将判负阈值(默认6次)

新增方法:
- `update_check_status()`: 更新将军状态并检查是否触发长将
- `get_perpetual_check_penalty()`: 获取长将惩罚值(用于训练)

### 2. 游戏引擎 (`game/game_engine.py`)

新增方法:
- `is_in_check(color)`: 检查某方是否被将军
- `_find_general(color)`: 查找某方将帅位置
- `has_non_check_response(color)`: 检查是否有非应将走法
- `check_perpetual_check()`: 检测长将并判罚

### 3. 训练集成 (`train_rl_ai_improved.py`)

- 在每步移动后添加长将惩罚到奖励值
- 根据连续将军次数递增惩罚(-0.005 → -0.02 → -0.1)
- 长将判负时正确记录胜负结果

## 长将判定规则

1. **触发条件**:
   - 某方连续将军达到6次(可配置)
   - 且每次对方都是被迫应将(没有非应将走法)

2. **判罚结果**:
   - 长将方判负
   - 对方获胜

3. **计数重置**:
   - 对方有非应将走法时重置
   - 没有将军时重置
   - 将军方切换时重置

## 训练奖励设计

连续将军惩罚梯度:
- 1-2次: -0.005 (轻微惩罚,允许必要的将军)
- 3-4次: -0.02 (中等惩罚,警告AI)
- 5次以上: -0.1 (严重惩罚,接近判负)
- 6次: 触发判负,失去整局

## 使用方法

### 测试长将检测:
```bash
python test_perpetual_check.py
```

### 训练时自动启用:
```bash
python train_rl_ai_improved.py --games 50 --iterations 300 ...
```

长将检测已完全集成,无需额外配置。

## 实现细节

### 将军检测算法:
1. 找到被检查方的将帅位置
2. 遍历攻击方所有已翻开的棋子
3. 检查每个棋子是否能合法移动到将帅位置
4. 任何一个能到达即判定为"将军"

### 应将判断算法:
1. 遍历被将军方所有棋子的所有合法移动
2. 对每个移动进行模拟(临时执行)
3. 检查模拟后是否仍被将军
4. 撤销模拟移动
5. 如果存在任何移动能解除将军,则有非应将走法

### 性能优化:
- 将帅位置查找: O(90) = O(1)
- 将军检测: O(32) = O(1) (最多32个棋子)
- 应将判断: O(32 × 平均合法移动数) ≈ O(200-300)
- 每步开销可接受,不影响训练速度

## 与三次重复的关系

- **三次重复**: 判和,双方责任相等
- **长将**: 判负,单方责任,违规方判负
- 两者可能同时触发,优先检测长将
- 检测顺序: 将死 → 长将 → 三次重复

## 注意事项

1. 暗棋不参与将军检测(只有翻开的棋子才能将军)
2. 将帅"面对面"的飞将不算长将(一次性将死)
3. 连续将军必须是"被迫应将",对方有选择则不算
4. 训练早期可能出现长将,随着训练会逐渐减少

## 后续优化方向

1. 添加"长捉"检测(连续追吃某个棋子)
2. 添加"一将一杀"等复杂规则
3. 可配置的阈值(当前硬编码为6次)
4. 更精细的惩罚梯度调整
